{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a5f0c0-ed69-4feb-879f-13f4815a553f",
   "metadata": {},
   "source": [
    "### W23P1 STAT 857 - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeaa731-0091-47eb-a686-9efc83077175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install xgboost lightgbm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f449ab-2b1f-4510-86ca-460f4d02d1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor \n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b3fbd8-4c4f-43c0-af78-2e9ec3015a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Reading the data\n",
    "train = pd.read_csv('Data/W23P1_train_final.csv')\n",
    "test = pd.read_csv('Data/W23P1_test_final.csv')\n",
    "sub = pd.read_csv('Data/W23P1_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd12d2e-2e22-494d-aeb6-74e15d20c2d9",
   "metadata": {},
   "source": [
    "### Baseline Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7dab9b-fec3-4d18-8154-346933fe078c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "X_train = train.drop(columns = ['fare_amount'])\n",
    "Y_train = train['fare_amount']\n",
    "\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c93da-2397-4fab-ad29-74d957e0d777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Random Forest Model:\n",
    "rf_md = RandomForestRegressor(max_depth = 3, n_estimators = 500).fit(X_train, Y_train)\n",
    "\n",
    "sub['fare_amount'] = rf_md.predict(X_test)\n",
    "\n",
    "sub.to_csv('Submissions/rf_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd80ba-a0fb-4fa0-826d-1d955fa10ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## XGBoost Model:\n",
    "XGB_md = XGBRegressor(tree_method = 'hist', colsample_bytree = 0.7, gamma = 0.8, learning_rate = 0.01, max_depth = 7, \n",
    "                      min_child_weight = 10, n_estimators = 1000, subsample = 0.7).fit(X_train, Y_train)\n",
    "\n",
    "sub['fare_amount'] = XGB_md.predict(X_test)\n",
    "\n",
    "sub.to_csv('Submissions/xgb_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2e279-fc33-4a50-abb0-1027d52796d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## LightGBM Model:\n",
    "lgb_md = LGBMRegressor(n_estimators = 1000, max_depth = 7, learning_rate = 0.01, num_leaves = 20, lambda_l1 = 3, lambda_l2 = 3, \n",
    "                       bagging_fraction = 0.7, feature_fraction = 0.7).fit(X_train, Y_train)\n",
    "\n",
    "sub['fare_amount'] = lgb_md.predict(X_test)\n",
    "\n",
    "sub.to_csv('Submissions/lgbm_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a75ef-42b2-4d4e-9b05-146f064cdb15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## CatBoost Model:\n",
    "cat_md = CatBoostRegressor(loss_function = 'RMSE', iterations = 1000, learning_rate = 0.01, depth = 7, random_strength = 0.5, \n",
    "                           bagging_temperature = 0.7, border_count = 30, l2_leaf_reg = 5, verbose = False).fit(X_train, Y_train)\n",
    "\n",
    "sub['fare_amount'] = cat_md.predict(X_test)\n",
    "\n",
    "sub.to_csv('Submissions/cat_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee0751-59c4-4af1-b6e8-b8e90b455f46",
   "metadata": {},
   "source": [
    "### Second Round of Models: with optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab968d4-c769-4664-bef0-c4baf436070c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Random Forest Model:\n",
    "rf_md = RandomForestRegressor(max_depth = 300, n_estimators = 12, min_samples_split = 5, \n",
    "                              min_samples_leaf = 6).fit(X_train, Y_train)\n",
    "\n",
    "rf_preds = rf_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = rf_preds\n",
    "\n",
    "sub.to_csv('Submissions/rf_rd2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa9f768-de38-4df1-b841-bad7939a337a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## XGBoost Model:\n",
    "XGB_md = XGBRegressor(tree_method = 'hist', n_estimators = 500, learning_rate = 0.02, max_depth = 5, gamma = 0.2, \n",
    "                      min_child_weight = 10, subsample = 0.94, colsample_bytree = 0.92, verbosity = 0).fit(X_train, Y_train)\n",
    "\n",
    "XGB_preds = XGB_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = XGB_preds\n",
    "\n",
    "sub.to_csv('Submissions/xgb_rd2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca6a0e-7157-483c-ad5c-fb75b74c8bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## LightGBM Model:\n",
    "lgbm_md = LGBMRegressor(boosting_type = 'dart', n_estimators = 600, learning_rate = 0.18, num_leaves = 8, max_depth = 8,\n",
    "                      subsample = 0.73, colsample_bytree = 0.86, random_state = 543, reg_alpha = 0.021, reg_lambda = 0.027, \n",
    "                        objective = 'rmse', verbosity = -1).fit(X_train, Y_train)\n",
    "\n",
    "lgbm_preds = lgbm_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = lgbm_preds\n",
    "\n",
    "sub.to_csv('Submissions/lgbm_rd2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa26da9c-c864-4fac-a3a1-5950a4adeed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Ensemble Model:\n",
    "\n",
    "## Constructing the training data\n",
    "rf_preds_train = rf_md.predict(X_train)\n",
    "XGB_preds_train = XGB_md.predict(X_train)\n",
    "lgbm_preds_train = lgbm_md.predict(X_train)\n",
    "\n",
    "X_train_ensemble = pd.DataFrame({'rf': rf_preds_train, 'xgb': XGB_preds_train, 'lgbm': lgbm_preds_train})\n",
    "X_test_ensemble = pd.DataFrame({'rf': rf_preds, 'xgb': XGB_preds, 'lgbm': lgbm_preds})\n",
    "\n",
    "## Building the model\n",
    "ensemble_md = RandomForestRegressor(max_depth = 3, n_estimators = 500).fit(X_train_ensemble, Y_train)\n",
    "\n",
    "sub['fare_amount'] = ensemble_md.predict(X_test_ensemble)\n",
    "\n",
    "sub.to_csv('Submissions/ensemble_rd2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f9990-8bb2-48c5-bd3d-51d4c8ef8346",
   "metadata": {},
   "source": [
    "### Third Round of Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c693f03-8358-4391-bc82-f30fd92ef884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "\n",
    "variables = ['distance', 'haversine', 'duration', 'passenger_count', 'pickup_day','Monday', 'Tuesday', 'Wednesday', 'Thursday',  \n",
    "             'Friday', 'Saturday','weekend', 'pickup_hour', 'rush_hour', 'overnight', 'pickup_LGA', 'dropoff_LGA', 'pickup_JFK', \n",
    "             'dropoff_JFK', 'pickup_EWR', 'dropoff_EWR', 'airport', 'change_borough', 'pickup_longitude', 'pickup_latitude', \n",
    "             'dropoff_longitude', 'dropoff_latitude']\n",
    "\n",
    "X_train = train[variables]\n",
    "Y_train = train['fare_amount']\n",
    "\n",
    "X_test = test[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e33e2-6bc8-41ea-9c08-403f2172841d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Random Forest Model:\n",
    "rf_md = RandomForestRegressor(max_depth = 300, n_estimators = 12, min_samples_split = 5, \n",
    "                              min_samples_leaf = 6).fit(X_train, Y_train)\n",
    "\n",
    "rf_preds = rf_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = rf_preds\n",
    "\n",
    "#sub.to_csv('Submissions/rf_rd3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadc3cc2-98d0-4ec7-9cc1-8c6e41139fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## XGBoost Model:\n",
    "XGB_md = XGBRegressor(tree_method = 'hist', n_estimators = 500, learning_rate = 0.02, max_depth = 5, gamma = 0.2, \n",
    "                      min_child_weight = 10, subsample = 0.94, colsample_bytree = 0.92, verbosity = 0).fit(X_train, Y_train)\n",
    "\n",
    "XGB_preds = XGB_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = XGB_preds\n",
    "\n",
    "#sub.to_csv('Submissions/xgb_rd3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74650e8-b9e9-43b7-a2f8-fa82c194e79c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## LightGBM Model:\n",
    "lgbm_md = LGBMRegressor(boosting_type = 'dart', n_estimators = 600, learning_rate = 0.18, num_leaves = 8, max_depth = 8,\n",
    "                      subsample = 0.73, colsample_bytree = 0.86, random_state = 543, reg_alpha = 0.021, reg_lambda = 0.027, \n",
    "                        objective = 'rmse', verbosity = -1).fit(X_train, Y_train)\n",
    "\n",
    "lgbm_preds = lgbm_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = lgbm_preds\n",
    "\n",
    "#sub.to_csv('Submissions/lgbm_rd3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed0133d-5c3e-4591-9177-7f2c17cb74cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Ensemble Model:\n",
    "\n",
    "## Constructing the training data\n",
    "rf_preds_train = rf_md.predict(X_train)\n",
    "XGB_preds_train = XGB_md.predict(X_train)\n",
    "lgbm_preds_train = lgbm_md.predict(X_train)\n",
    "\n",
    "X_train_ensemble = pd.DataFrame({'rf': rf_preds_train, 'xgb': XGB_preds_train, 'lgbm': lgbm_preds_train})\n",
    "X_test_ensemble = pd.DataFrame({'rf': rf_preds, 'xgb': XGB_preds, 'lgbm': lgbm_preds})\n",
    "\n",
    "## Building the model\n",
    "ensemble_md = RandomForestRegressor(max_depth = 3, n_estimators = 500).fit(X_train_ensemble, Y_train)\n",
    "\n",
    "sub['fare_amount'] = ensemble_md.predict(X_test_ensemble)\n",
    "\n",
    "sub.to_csv('Submissions/ensemble_rd3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dbd065-1056-4846-9824-3fe07237d40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ins = test.merge(train, how = 'inner', on = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'])\n",
    "ins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8916a-90fd-4e5b-a2f9-d33fd4878cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub['fare_amount'] = (rf_preds + XGB_preds + lgbm_preds) / 3\n",
    "print(np.mean(sub['fare_amount']))\n",
    "\n",
    "ind = [631,  1044,  8718,  9614,  9784, 11654, 12032, 12810, 13254, 13374, 16042, 17660, 18328, 18930, 20616, 22499, 22829, 23702, \\\n",
    "       25597, 25958, 26925, 27347, 27552, 31726, 33099, 33668]\n",
    "fare = [6.5,  6.5,  6.66666667, 6.5, 6.5, 11.4, 14.25, 14.25, 6.5, 5.5, 51.625, 51.625, 9.5, 5.5, 11.4, 18.75, 13.5, 6.5, 18.75, 14.25, \\\n",
    "        6.66666667, 7.75, 6.5, 14.25, 6.5, 14.25]    \n",
    "\n",
    "sub['fare_amount'].iloc[ind] = fare\n",
    "\n",
    "print(np.mean(sub['fare_amount']))\n",
    "sub.to_csv('Submissions/ensemble_average4.csv', index = False)\n",
    "\n",
    "# sub['fare_amount'] = (rf_preds + 3*XGB_preds + 2*lgbm_preds) / 6\n",
    "\n",
    "# sub.to_csv('Submissions/ensemble_average3.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea30e39-5c8f-4284-bd49-d606662ae3c2",
   "metadata": {},
   "source": [
    "### Fourth Round: Optimized HPs and top-10 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61433e3f-a816-4316-bc71-1b8381b13ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "\n",
    "variables = ['distance', 'haversine', 'dropoff_longitude', 'duration', 'pickup_longitude', 'dropoff_EWR', 'EWR', \n",
    "             'dropoff_airport', 'pickup_airport', 'dropoff_JFK']\n",
    "\n",
    "X_train = train[variables]\n",
    "Y_train = train['fare_amount']\n",
    "\n",
    "X_test = test[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae3120-2d3d-4d6b-bf19-db72b66eef3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Random Forest Model:\n",
    "rf_md = RandomForestRegressor(max_depth = 100, n_estimators = 10, min_samples_split = 8, \n",
    "                              min_samples_leaf = 8).fit(X_train, Y_train)\n",
    "\n",
    "rf_preds = rf_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = rf_preds\n",
    "\n",
    "sub.to_csv('Submissions/rf_rd4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e620700-4082-44d2-b8e8-3e856b443c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## XGBoost Model:\n",
    "XGB_md = XGBRegressor(tree_method = 'hist', n_estimators = 500, learning_rate = 0.01, max_depth = 10, gamma = 0.13, \n",
    "                      min_child_weight = 15, subsample = 0.71, colsample_bytree = 0.7, verbosity = 0).fit(X_train, Y_train)\n",
    "\n",
    "XGB_preds = XGB_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = XGB_preds\n",
    "\n",
    "sub.to_csv('Submissions/xgb_rd4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57dd2e6-31ff-45c4-8dda-f251f75c8b45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## LightGBM Model:\n",
    "lgbm_md = LGBMRegressor(boosting_type = 'dart', n_estimators = 500, learning_rate = 0.1, num_leaves = 29, max_depth = 3,\n",
    "                      subsample = 0.93, colsample_bytree = 0.73, random_state = 433, reg_alpha = 0.065, reg_lambda = 0.047, \n",
    "                        objective = 'rmse', verbosity = -1).fit(X_train, Y_train)\n",
    "\n",
    "lgbm_preds = lgbm_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = lgbm_preds\n",
    "\n",
    "sub.to_csv('Submissions/lgbm_rd4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e8a45d-ca7d-4946-95e5-d6236a7f4f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Ensemble Model:\n",
    "\n",
    "## Constructing the training data\n",
    "rf_preds_train = rf_md.predict(X_train)\n",
    "XGB_preds_train = XGB_md.predict(X_train)\n",
    "lgbm_preds_train = lgbm_md.predict(X_train)\n",
    "\n",
    "X_train_ensemble = pd.DataFrame({'rf': rf_preds_train, 'xgb': XGB_preds_train, 'lgbm': lgbm_preds_train})\n",
    "X_test_ensemble = pd.DataFrame({'rf': rf_preds, 'xgb': XGB_preds, 'lgbm': lgbm_preds})\n",
    "\n",
    "## Building the model\n",
    "ensemble_md = RandomForestRegressor(max_depth = 5, n_estimators = 1000).fit(X_train_ensemble, Y_train)\n",
    "\n",
    "sub['fare_amount'] = ensemble_md.predict(X_test_ensemble)\n",
    "\n",
    "sub.to_csv('Submissions/ensemble_rd4.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589748d-1f8e-4fe0-b032-b79350483cdc",
   "metadata": {},
   "source": [
    "### Fifth Round of Models: Optimized hps, new features, with top __ features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ef0e4-efe9-4660-abda-6123b82873ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "X_train_XGB = train.drop(columns = ['fare_amount'])\n",
    "Y_train_XGB = train['fare_amount']\n",
    "\n",
    "X_test = test\n",
    "\n",
    "## XGBoost Model:\n",
    "XGB_md = XGBRegressor(tree_method = 'hist', n_estimators = 300, learning_rate = 0.02, max_depth = 5, gamma = 0.2, \n",
    "                      min_child_weight = 6, subsample = 0.99, colsample_bytree = 0.74, verbosity = 0).fit(X_train_XGB, Y_train_XGB)\n",
    "\n",
    "XGB_preds = XGB_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = XGB_preds\n",
    "\n",
    "sub.to_csv('Submissions/xgb_rd3a.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee33dafd-abb1-4c75-b443-e4727d8801a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "X_train_XGB = train.drop(columns = ['fare_amount', 'Tuesday', 'Wednesday', 'dropoff_LGA', 'pickup_JFK', 'pickup_EWR', 'dropoff_EWR', \n",
    "                                   'pickup_bronx', 'pickup_brooklyn', 'pickup_staten_island', 'dropoff_bronx', 'dropoff_brooklyn', \n",
    "                                   'dropoff_queens', 'dropoff_staten_island'])\n",
    "Y_train_XGB = train['fare_amount']\n",
    "\n",
    "X_test = test.drop(columns = ['Tuesday', 'Wednesday', 'dropoff_LGA', 'pickup_JFK', 'pickup_EWR', 'dropoff_EWR', 'pickup_bronx', \n",
    "                              'pickup_brooklyn', 'pickup_staten_island', 'dropoff_bronx', 'dropoff_brooklyn', 'dropoff_queens', \n",
    "                              'dropoff_staten_island'])\n",
    "\n",
    "## XGBoost Model:\n",
    "XGB_md = XGBRegressor(tree_method = 'hist', n_estimators = 300, learning_rate = 0.02, max_depth = 5, gamma = 0.2, \n",
    "                      min_child_weight = 6, subsample = 0.99, colsample_bytree = 0.74, verbosity = 0).fit(X_train_XGB, Y_train_XGB)\n",
    "\n",
    "XGB_preds = XGB_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = XGB_preds\n",
    "\n",
    "sub.to_csv('Submissions/xgb_rd3b.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8bb192-1b22-4c14-9cd4-8226dd42c68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "X_train_lgbm = train.drop(columns = ['fare_amount'])\n",
    "Y_train_lgbm = train['fare_amount']\n",
    "\n",
    "X_test = test\n",
    "\n",
    "## LightGBM Model:\n",
    "lgbm_md = LGBMRegressor(boosting_type = 'dart', n_estimators = 1200, learning_rate = 0.06, num_leaves = 9, max_depth = 3,\n",
    "                      subsample = 0.82, colsample_bytree = 0.9, random_state = 660, reg_alpha = 0.042, reg_lambda = 0.066, \n",
    "                        objective = 'rmse', verbosity = -1).fit(X_train_lgbm, Y_train_lgbm)\n",
    "\n",
    "lgbm_preds = lgbm_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = lgbm_preds\n",
    "\n",
    "sub.to_csv('Submissions/lgbm_rd3a.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6907d5-fa80-4f98-9b40-a7d649c9743b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "X_train_lgbm = train.drop(columns = ['fare_amount', 'Tuesday', 'Wednesday', 'dropoff_LGA', 'pickup_JFK', 'pickup_EWR', 'dropoff_EWR', \n",
    "                                    'pickup_bronx', 'pickup_brooklyn', 'pickup_staten_island', 'dropoff_bronx', 'dropoff_brooklyn', \n",
    "                                    'dropoff_queens', 'dropoff_staten_island'])\n",
    "Y_train_lgbm = train['fare_amount']\n",
    "\n",
    "X_test = test.drop(columns = ['Tuesday', 'Wednesday', 'dropoff_LGA', 'pickup_JFK', 'pickup_EWR', 'dropoff_EWR', 'pickup_bronx', \n",
    "                              'pickup_brooklyn', 'pickup_staten_island', 'dropoff_bronx', 'dropoff_brooklyn', 'dropoff_queens', \n",
    "                              'dropoff_staten_island'])\n",
    "\n",
    "## LightGBM Model:\n",
    "lgbm_md = LGBMRegressor(boosting_type = 'dart', n_estimators = 1200, learning_rate = 0.06, num_leaves = 9, max_depth = 3,\n",
    "                      subsample = 0.82, colsample_bytree = 0.9, random_state = 660, reg_alpha = 0.042, reg_lambda = 0.066, \n",
    "                        objective = 'rmse', verbosity = -1).fit(X_train_lgbm, Y_train_lgbm)\n",
    "\n",
    "lgbm_preds = lgbm_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = lgbm_preds\n",
    "\n",
    "sub.to_csv('Submissions/lgbm_rd3b.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98497c19-c5cc-4433-9f98-e1279c204e51",
   "metadata": {},
   "source": [
    "## Using K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756fd83-c3ce-4e8e-8385-501a56fbe7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Reading the data\n",
    "train = pd.read_csv('W23P1_training.csv')\n",
    "test = pd.read_csv('W23P1_testing.csv')\n",
    "sub = pd.read_csv('Data/W23P1_sample_submission.csv')\n",
    "\n",
    "## Defining the input and target variables\n",
    "X_train = train.drop(columns = ['uid', 'fare_amount'])\n",
    "Y_train = train['fare_amount']\n",
    "\n",
    "X_test = test.drop(columns = ['uid', 'fare_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8870e1-43d1-42df-9997-f5602b7d8526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 10-Fold CV with RandomForest\n",
    "kf = KFold(n_splits = 10, random_state = 42, shuffle = True)\n",
    "\n",
    "## Defining lists to store results \n",
    "train_error = list(); validation_error = list()\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    \n",
    "    ## Defining the training and validation data\n",
    "    X_training = X_train.iloc[train_index]; Y_training = Y_train.iloc[train_index]\n",
    "    X_validation = X_train.iloc[test_index]; Y_validation = Y_train.iloc[test_index]\n",
    "    \n",
    "    rf_md = RandomForestRegressor(max_depth = 3, n_estimators = 100).fit(X_training, Y_training)\n",
    "    \n",
    "    training_preds = rf_md.predict(X_training)\n",
    "    validation_preds = rf_md.predict(X_validation)\n",
    "    \n",
    "    training_mse = mean_squared_error(Y_training, training_preds, squared = False)\n",
    "    validation_mse = mean_squared_error(Y_validation, validation_preds, squared = False)\n",
    "    \n",
    "    train_error.append(training_mse)\n",
    "    validation_error.append(validation_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dca9f3-0c21-4a48-86c0-f4391399da13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.mean(train_error))\n",
    "print(np.mean(validation_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1101319d-e703-4d1a-8d17-5ef3876a5406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 10-Fold CV with XGBoost\n",
    "kf = KFold(n_splits = 10, random_state = 42, shuffle = True)\n",
    "\n",
    "## Defining lists to store results \n",
    "train_error = list(); validation_error = list(); preds = list()\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    \n",
    "    ## Defining the training and validation data\n",
    "    X_training = X_train.iloc[train_index]; Y_training = Y_train.iloc[train_index]\n",
    "    X_validation = X_train.iloc[test_index]; Y_validation = Y_train.iloc[test_index]\n",
    "    \n",
    "    xgb_md = XGBRegressor(tree_method = 'hist', learning_rate = 0.1, subsample = 0.9).fit(X_training, Y_training)\n",
    "    \n",
    "    training_preds = xgb_md.predict(X_training)\n",
    "    validation_preds = xgb_md.predict(X_validation)\n",
    "    testing_preds = xgb_md.predict(X_test)\n",
    "    \n",
    "    training_mse = mean_squared_error(Y_training, training_preds, squared = False)\n",
    "    validation_mse = mean_squared_error(Y_validation, validation_preds, squared = False)\n",
    "    \n",
    "    train_error.append(training_mse)\n",
    "    validation_error.append(validation_mse)\n",
    "    preds.append(testing_preds)\n",
    "\n",
    "print(np.mean(train_error))\n",
    "print(np.mean(validation_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8848ea-a631-4b8d-b3da-f1f39480492b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub['fare_amount'] = np.mean(pd.DataFrame(np.array(preds).reshape((35000, 10))), axis = 1)\n",
    "sub.to_csv('Submissions/xgb_kfold.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03c866d-66f5-4886-9e5a-ebcb33457441",
   "metadata": {},
   "source": [
    "## Final Shot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f73a2cf-afde-4efe-9254-a2c7dfea657e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Reading the data\n",
    "train = pd.read_csv('Data/final_shot_train.csv')\n",
    "test = pd.read_csv('Data/final_shot_test.csv')\n",
    "sub = pd.read_csv('Data/W23P1_sample_submission.csv')\n",
    "\n",
    "## Defining inputs and target\n",
    "X = train[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'haversine', 'same_lat', \n",
    "           'same_coord_rounded', 'pickup_LGA', 'dropoff_LGA', 'LGA', 'pickup_JFK', 'dropoff_JFK', 'JFK', 'pickup_EWR', \n",
    "           'dropoff_EWR', 'EWR', 'pickup_airport', 'dropoff_airport', 'airport', 'change_borough', 'pickup_bronx', \n",
    "           'pickup_brooklyn', 'pickup_manhattan', 'pickup_other', 'pickup_queens', 'pickup_staten_island', 'dropoff_bronx', \n",
    "           'dropoff_brooklyn', 'dropoff_manhattan', 'dropoff_other', 'dropoff_queens', 'dropoff_staten_island', 'time_estimate', \n",
    "           'distance', 'duration']]\n",
    "Y = train['fare_amount']\n",
    "\n",
    "## Splitting into training and validation sets\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size = 0.3, random_state = 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90c33a9f-0f4d-4f18-a2ce-c81c7d598a5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.984813327895632\n",
      "2.5179201755757727\n"
     ]
    }
   ],
   "source": [
    "## Random Forest\n",
    "rf_md = RandomForestRegressor(max_depth = 7, n_estimators = 300, min_samples_leaf = 100, random_state = 365).fit(X_train, Y_train)\n",
    "rf_train_preds = rf_md.predict(X_train); print(mean_squared_error(Y_train, rf_train_preds, squared = False))\n",
    "rf_val_preds = rf_md.predict(X_validation); print(mean_squared_error(Y_validation, rf_val_preds, squared = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ee4ab-d95d-4b9c-a817-03b9ee8575cd",
   "metadata": {},
   "source": [
    "max_depth = 7, n_estimators = 300, min_samples_leaf = 250, random_state = 365 --> 3.12 2.65\n",
    "\n",
    "max_depth = 7, n_estimators = 300, min_samples_leaf = 200, random_state = 365 --> 3.11 2.63\n",
    "\n",
    "max_depth = 7, n_estimators = 300, min_samples_leaf = 100, random_state = 365 --> 2.98 2.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f708737-763f-4b67-82e7-ac4cedf1a514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.700086224274026\n",
      "2.3675831409458543\n"
     ]
    }
   ],
   "source": [
    "## XGBoost\n",
    "xgb_md = XGBRegressor(tree_method = 'hist', n_estimators = 700, learning_rate = 0.05, max_depth = 8, gamma = 50, \n",
    "                      min_child_weight = 100, subsample = 1, colsample_bytree = 1, seed = 365).fit(X_train, Y_train)\n",
    "xgb_train_preds = xgb_md.predict(X_train); print(mean_squared_error(Y_train, xgb_train_preds, squared = False))\n",
    "xgb_val_preds = xgb_md.predict(X_validation); print(mean_squared_error(Y_validation, xgb_val_preds, squared = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3624eaa4-195d-4aec-8c83-214cb5b86f44",
   "metadata": {},
   "source": [
    "n_estimators = 800, learning_rate = 0.09, max_depth = 8, gamma = 300, min_child_weight = 400 --> 3.01 2.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5d590f5-774a-406e-8712-84def00cb37f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "2.4234469282543722\n",
      "2.352782055386873\n"
     ]
    }
   ],
   "source": [
    "## LGBM:\n",
    "lgbm_md = LGBMRegressor(n_estimators = 1000, learning_rate = 0.05, min_data_in_leaf = 100, max_depth = 6, \n",
    "                        subsample = 1, colsample_bytree = 1, random_state = 365, reg_alpha = 1, reg_lambda = 1, \n",
    "                        objective = 'rmse', verbosity = -1).fit(X_train, Y_train)\n",
    "lgbm_train_preds = lgbm_md.predict(X_train); print(mean_squared_error(Y_train, lgbm_train_preds, squared = False))\n",
    "lgbm_val_preds = lgbm_md.predict(X_validation); print(mean_squared_error(Y_validation, lgbm_val_preds, squared = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7816f4-414c-492f-8cee-3e010e798733",
   "metadata": {},
   "source": [
    "n_estimators = 1000, learning_rate = 0.01, min_data_in_leaf = 400, max_depth = 5, \n",
    "                        subsample = 1, colsample_bytree = 1, random_state = 365, reg_alpha = 20, reg_lambda = 20, \n",
    "                        objective = 'rmse', verbosity = -1 --> 2.85 2.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "081b9b6c-7505-423c-a499-00cc637286fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    }
   ],
   "source": [
    "## Defining inputs and target\n",
    "X = train[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'haversine', 'same_lat', \n",
    "           'same_coord_rounded', 'pickup_LGA', 'dropoff_LGA', 'LGA', 'pickup_JFK', 'dropoff_JFK', 'JFK', 'pickup_EWR', \n",
    "           'dropoff_EWR', 'EWR', 'pickup_airport', 'dropoff_airport', 'airport', 'change_borough', 'pickup_bronx', \n",
    "           'pickup_brooklyn', 'pickup_manhattan', 'pickup_other', 'pickup_queens', 'pickup_staten_island', 'dropoff_bronx', \n",
    "           'dropoff_brooklyn', 'dropoff_manhattan', 'dropoff_other', 'dropoff_queens', 'dropoff_staten_island', 'time_estimate', \n",
    "           'distance', 'duration']]\n",
    "Y = train['fare_amount']\n",
    "\n",
    "X_test = test[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'haversine', 'same_lat', \n",
    "               'same_coord_rounded', 'pickup_LGA', 'dropoff_LGA', 'LGA', 'pickup_JFK', 'dropoff_JFK', 'JFK', 'pickup_EWR', \n",
    "               'dropoff_EWR', 'EWR', 'pickup_airport', 'dropoff_airport', 'airport', 'change_borough', 'pickup_bronx', \n",
    "               'pickup_brooklyn', 'pickup_manhattan', 'pickup_other', 'pickup_queens', 'pickup_staten_island', 'dropoff_bronx', \n",
    "               'dropoff_brooklyn', 'dropoff_manhattan', 'dropoff_other', 'dropoff_queens', 'dropoff_staten_island', 'time_estimate', \n",
    "               'distance', 'duration']]\n",
    "\n",
    "## Building last chance models\n",
    "rf_md = RandomForestRegressor(max_depth = 7, n_estimators = 300, min_samples_leaf = 100, random_state = 365).fit(X, Y)\n",
    "\n",
    "xgb_md = XGBRegressor(tree_method = 'hist', n_estimators = 700, learning_rate = 0.05, max_depth = 8, gamma = 50, \n",
    "                      min_child_weight = 100, subsample = 1, colsample_bytree = 1, seed = 365).fit(X, Y)\n",
    "\n",
    "lgbm_md = LGBMRegressor(n_estimators = 1000, learning_rate = 0.05, min_data_in_leaf = 100, max_depth = 6, subsample = 1, \n",
    "                        colsample_bytree = 1, random_state = 365, reg_alpha = 1, reg_lambda = 1, objective = 'rmse').fit(X, Y)\n",
    "\n",
    "## Predicting on the testing set\n",
    "rf_md_preds = rf_md.predict(X_test); rf_md_preds = np.where(rf_md_preds < 2.5, 2.5, rf_md_preds)\n",
    "xgb_md_preds = xgb_md.predict(X_test); xgb_md_preds = np.where(xgb_md_preds < 2.5, 2.5, xgb_md_preds)\n",
    "lgbm_md_preds = lgbm_md.predict(X_test); lgbm_md_preds = np.where(lgbm_md_preds < 2.5, 2.5, lgbm_md_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e9bac9-47be-41ae-830a-018474e6552c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Constructing ensemble predictions\n",
    "ensemble_final1 = (rf_md_preds + xgb_md_preds + lgbm_md_preds) / 3\n",
    "\n",
    "## Getting predictions in a csv file \n",
    "sub['fare_amount'] = ensemble_final1\n",
    "sub.to_csv('Submissions/ensemble_final1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f54b8f7-35de-45f5-8ef5-b312feaf1b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best = pd.read_csv('Submissions/ensemble_average_adjusted.csv')\n",
    "best2 = pd.read_csv('Submissions/ensemble_average2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fd4f2c9-b032-4d5c-ad15-52fb813889ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Constructing ensemble predictions\n",
    "ensemble_final2 = (best['fare_amount'] + best2['fare_amount'] + rf_md_preds + xgb_md_preds + lgbm_md_preds) / 5\n",
    "\n",
    "## Getting predictions in a csv file \n",
    "sub['fare_amount'] = ensemble_final2\n",
    "sub.to_csv('Submissions/ensemble_final2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ba6e19e-1c7d-48f7-ae7b-c02efde53ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_preds = np.where(best['fare_amount'] < 2.5, 2.5, best['fare_amount'])\n",
    "best_preds2 = np.where(best2['fare_amount'] < 2.5, 2.5, best2['fare_amount'])\n",
    "\n",
    "ensemble_final3 = (2*best_preds + best_preds2) / 3\n",
    "\n",
    "## Getting predictions in a csv file \n",
    "sub['fare_amount'] = ensemble_final3\n",
    "sub.to_csv('Submissions/ensemble_final3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b624b841-81f7-43bb-8ea9-f658d242c950",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 85.90644838, 104.38365368, 105.98494003,  81.79215973,\n",
       "        85.20422355,  85.40628672,  83.26933383,  87.57049199,\n",
       "        85.96743854,  86.53929781,  97.64057864,  88.07223788,\n",
       "        93.90235397])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_preds[best_preds > 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "94301de5-7a1f-4ccd-99e2-5b410c7bf302",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 85.73042133, 105.79975235, 107.36563559,  82.5407642 ,\n",
       "        84.82433852,  85.20584115,  83.24782316,  87.68651055,\n",
       "        85.64669273,  86.62645379,  98.42243436,  89.07372489,\n",
       "        93.77715118])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_final3[ensemble_final3 > 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3f924be-8a92-4261-9bbe-29d5d04e9a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble_final4 = (2*best_preds + best_preds2) / 3\n",
    "\n",
    "ensemble_final4 = np.where(ensemble_final4 > 100, 120, ensemble_final4)\n",
    "\n",
    "## Getting predictions in a csv file \n",
    "sub['fare_amount'] = ensemble_final4\n",
    "sub.to_csv('Submissions/ensemble_final4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc30ce-a408-421f-8175-7b0d123b8ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
