{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a5f0c0-ed69-4feb-879f-13f4815a553f",
   "metadata": {},
   "source": [
    "### W23P1 STAT 857 - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeaa731-0091-47eb-a686-9efc83077175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install xgboost lightgbm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f449ab-2b1f-4510-86ca-460f4d02d1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor \n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b3fbd8-4c4f-43c0-af78-2e9ec3015a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Reading the data\n",
    "train = pd.read_csv('Data/W23P1_train_final.csv')\n",
    "test = pd.read_csv('Data/W23P1_test_final.csv')\n",
    "sub = pd.read_csv('Data/W23P1_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd12d2e-2e22-494d-aeb6-74e15d20c2d9",
   "metadata": {},
   "source": [
    "### Baseline Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7dab9b-fec3-4d18-8154-346933fe078c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "X_train = train.drop(columns = ['fare_amount'])\n",
    "Y_train = train['fare_amount']\n",
    "\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c93da-2397-4fab-ad29-74d957e0d777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Random Forest Model:\n",
    "rf_md = RandomForestRegressor(max_depth = 3, n_estimators = 500).fit(X_train, Y_train)\n",
    "\n",
    "sub['fare_amount'] = rf_md.predict(X_test)\n",
    "\n",
    "sub.to_csv('Submissions/rf_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd80ba-a0fb-4fa0-826d-1d955fa10ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## XGBoost Model:\n",
    "XGB_md = XGBRegressor(tree_method = 'hist', colsample_bytree = 0.7, gamma = 0.8, learning_rate = 0.01, max_depth = 7, \n",
    "                      min_child_weight = 10, n_estimators = 1000, subsample = 0.7).fit(X_train, Y_train)\n",
    "\n",
    "sub['fare_amount'] = XGB_md.predict(X_test)\n",
    "\n",
    "sub.to_csv('Submissions/xgb_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2e279-fc33-4a50-abb0-1027d52796d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## LightGBM Model:\n",
    "lgb_md = LGBMRegressor(n_estimators = 1000, max_depth = 7, learning_rate = 0.01, num_leaves = 20, lambda_l1 = 3, lambda_l2 = 3, \n",
    "                       bagging_fraction = 0.7, feature_fraction = 0.7).fit(X_train, Y_train)\n",
    "\n",
    "sub['fare_amount'] = lgb_md.predict(X_test)\n",
    "\n",
    "sub.to_csv('Submissions/lgbm_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a75ef-42b2-4d4e-9b05-146f064cdb15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## CatBoost Model:\n",
    "cat_md = CatBoostRegressor(loss_function = 'RMSE', iterations = 1000, learning_rate = 0.01, depth = 7, random_strength = 0.5, \n",
    "                           bagging_temperature = 0.7, border_count = 30, l2_leaf_reg = 5, verbose = False).fit(X_train, Y_train)\n",
    "\n",
    "sub['fare_amount'] = cat_md.predict(X_test)\n",
    "\n",
    "sub.to_csv('Submissions/cat_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee0751-59c4-4af1-b6e8-b8e90b455f46",
   "metadata": {},
   "source": [
    "### Second Round of Models: with optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab968d4-c769-4664-bef0-c4baf436070c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Random Forest Model:\n",
    "rf_md = RandomForestRegressor(max_depth = 300, n_estimators = 12, min_samples_split = 5, \n",
    "                              min_samples_leaf = 6).fit(X_train, Y_train)\n",
    "\n",
    "rf_preds = rf_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = rf_preds\n",
    "\n",
    "sub.to_csv('Submissions/rf_rd2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa9f768-de38-4df1-b841-bad7939a337a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## XGBoost Model:\n",
    "XGB_md = XGBRegressor(tree_method = 'hist', n_estimators = 500, learning_rate = 0.02, max_depth = 5, gamma = 0.2, \n",
    "                      min_child_weight = 10, subsample = 0.94, colsample_bytree = 0.92, verbosity = 0).fit(X_train, Y_train)\n",
    "\n",
    "XGB_preds = XGB_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = XGB_preds\n",
    "\n",
    "sub.to_csv('Submissions/xgb_rd2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca6a0e-7157-483c-ad5c-fb75b74c8bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## LightGBM Model:\n",
    "lgbm_md = LGBMRegressor(boosting_type = 'dart', n_estimators = 600, learning_rate = 0.18, num_leaves = 8, max_depth = 8,\n",
    "                      subsample = 0.73, colsample_bytree = 0.86, random_state = 543, reg_alpha = 0.021, reg_lambda = 0.027, \n",
    "                        objective = 'rmse', verbosity = -1).fit(X_train, Y_train)\n",
    "\n",
    "lgbm_preds = lgbm_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = lgbm_preds\n",
    "\n",
    "sub.to_csv('Submissions/lgbm_rd2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa26da9c-c864-4fac-a3a1-5950a4adeed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Ensemble Model:\n",
    "\n",
    "## Constructing the training data\n",
    "rf_preds_train = rf_md.predict(X_train)\n",
    "XGB_preds_train = XGB_md.predict(X_train)\n",
    "lgbm_preds_train = lgbm_md.predict(X_train)\n",
    "\n",
    "X_train_ensemble = pd.DataFrame({'rf': rf_preds_train, 'xgb': XGB_preds_train, 'lgbm': lgbm_preds_train})\n",
    "X_test_ensemble = pd.DataFrame({'rf': rf_preds, 'xgb': XGB_preds, 'lgbm': lgbm_preds})\n",
    "\n",
    "## Building the model\n",
    "ensemble_md = RandomForestRegressor(max_depth = 3, n_estimators = 500).fit(X_train_ensemble, Y_train)\n",
    "\n",
    "sub['fare_amount'] = ensemble_md.predict(X_test_ensemble)\n",
    "\n",
    "sub.to_csv('Submissions/ensemble_rd2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f9990-8bb2-48c5-bd3d-51d4c8ef8346",
   "metadata": {},
   "source": [
    "### Third Round of Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c693f03-8358-4391-bc82-f30fd92ef884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "\n",
    "variables = ['distance', 'haversine', 'duration', 'passenger_count', 'pickup_day','Monday', 'Tuesday', 'Wednesday', 'Thursday',  \n",
    "             'Friday', 'Saturday','weekend', 'pickup_hour', 'rush_hour', 'overnight', 'pickup_LGA', 'dropoff_LGA', 'pickup_JFK', \n",
    "             'dropoff_JFK', 'pickup_EWR', 'dropoff_EWR', 'airport', 'change_borough', 'pickup_longitude', 'pickup_latitude', \n",
    "             'dropoff_longitude', 'dropoff_latitude']\n",
    "\n",
    "X_train = train[variables]\n",
    "Y_train = train['fare_amount']\n",
    "\n",
    "X_test = test[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336e33e2-6bc8-41ea-9c08-403f2172841d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Random Forest Model:\n",
    "rf_md = RandomForestRegressor(max_depth = 300, n_estimators = 12, min_samples_split = 5, \n",
    "                              min_samples_leaf = 6).fit(X_train, Y_train)\n",
    "\n",
    "rf_preds = rf_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = rf_preds\n",
    "\n",
    "sub.to_csv('Submissions/rf_rd3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cadc3cc2-98d0-4ec7-9cc1-8c6e41139fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## XGBoost Model:\n",
    "XGB_md = XGBRegressor(tree_method = 'hist', n_estimators = 500, learning_rate = 0.02, max_depth = 5, gamma = 0.2, \n",
    "                      min_child_weight = 10, subsample = 0.94, colsample_bytree = 0.92, verbosity = 0).fit(X_train, Y_train)\n",
    "\n",
    "XGB_preds = XGB_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = XGB_preds\n",
    "\n",
    "sub.to_csv('Submissions/xgb_rd3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c74650e8-b9e9-43b7-a2f8-fa82c194e79c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## LightGBM Model:\n",
    "lgbm_md = LGBMRegressor(boosting_type = 'dart', n_estimators = 600, learning_rate = 0.18, num_leaves = 8, max_depth = 8,\n",
    "                      subsample = 0.73, colsample_bytree = 0.86, random_state = 543, reg_alpha = 0.021, reg_lambda = 0.027, \n",
    "                        objective = 'rmse', verbosity = -1).fit(X_train, Y_train)\n",
    "\n",
    "lgbm_preds = lgbm_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = lgbm_preds\n",
    "\n",
    "sub.to_csv('Submissions/lgbm_rd3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eed0133d-5c3e-4591-9177-7f2c17cb74cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Ensemble Model:\n",
    "\n",
    "## Constructing the training data\n",
    "rf_preds_train = rf_md.predict(X_train)\n",
    "XGB_preds_train = XGB_md.predict(X_train)\n",
    "lgbm_preds_train = lgbm_md.predict(X_train)\n",
    "\n",
    "X_train_ensemble = pd.DataFrame({'rf': rf_preds_train, 'xgb': XGB_preds_train, 'lgbm': lgbm_preds_train})\n",
    "X_test_ensemble = pd.DataFrame({'rf': rf_preds, 'xgb': XGB_preds, 'lgbm': lgbm_preds})\n",
    "\n",
    "## Building the model\n",
    "ensemble_md = RandomForestRegressor(max_depth = 3, n_estimators = 500).fit(X_train_ensemble, Y_train)\n",
    "\n",
    "sub['fare_amount'] = ensemble_md.predict(X_test_ensemble)\n",
    "\n",
    "sub.to_csv('Submissions/ensemble_rd3.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea30e39-5c8f-4284-bd49-d606662ae3c2",
   "metadata": {},
   "source": [
    "### Fourth Round: Optimized HPs and top-10 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61433e3f-a816-4316-bc71-1b8381b13ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "\n",
    "variables = ['distance', 'haversine', 'dropoff_longitude', 'duration', 'pickup_longitude', 'dropoff_EWR', 'EWR', \n",
    "             'dropoff_airport', 'pickup_airport', 'dropoff_JFK']\n",
    "\n",
    "X_train = train[variables]\n",
    "Y_train = train['fare_amount']\n",
    "\n",
    "X_test = test[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ae3120-2d3d-4d6b-bf19-db72b66eef3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Random Forest Model:\n",
    "rf_md = RandomForestRegressor(max_depth = 100, n_estimators = 10, min_samples_split = 8, \n",
    "                              min_samples_leaf = 8).fit(X_train, Y_train)\n",
    "\n",
    "rf_preds = rf_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = rf_preds\n",
    "\n",
    "sub.to_csv('Submissions/rf_rd4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e620700-4082-44d2-b8e8-3e856b443c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## XGBoost Model:\n",
    "XGB_md = XGBRegressor(tree_method = 'hist', n_estimators = 500, learning_rate = 0.01, max_depth = 10, gamma = 0.13, \n",
    "                      min_child_weight = 15, subsample = 0.71, colsample_bytree = 0.7, verbosity = 0).fit(X_train, Y_train)\n",
    "\n",
    "XGB_preds = XGB_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = XGB_preds\n",
    "\n",
    "sub.to_csv('Submissions/xgb_rd4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57dd2e6-31ff-45c4-8dda-f251f75c8b45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## LightGBM Model:\n",
    "lgbm_md = LGBMRegressor(boosting_type = 'dart', n_estimators = 500, learning_rate = 0.1, num_leaves = 29, max_depth = 3,\n",
    "                      subsample = 0.93, colsample_bytree = 0.73, random_state = 433, reg_alpha = 0.065, reg_lambda = 0.047, \n",
    "                        objective = 'rmse', verbosity = -1).fit(X_train, Y_train)\n",
    "\n",
    "lgbm_preds = lgbm_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = lgbm_preds\n",
    "\n",
    "sub.to_csv('Submissions/lgbm_rd4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e8a45d-ca7d-4946-95e5-d6236a7f4f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Ensemble Model:\n",
    "\n",
    "## Constructing the training data\n",
    "rf_preds_train = rf_md.predict(X_train)\n",
    "XGB_preds_train = XGB_md.predict(X_train)\n",
    "lgbm_preds_train = lgbm_md.predict(X_train)\n",
    "\n",
    "X_train_ensemble = pd.DataFrame({'rf': rf_preds_train, 'xgb': XGB_preds_train, 'lgbm': lgbm_preds_train})\n",
    "X_test_ensemble = pd.DataFrame({'rf': rf_preds, 'xgb': XGB_preds, 'lgbm': lgbm_preds})\n",
    "\n",
    "## Building the model\n",
    "ensemble_md = RandomForestRegressor(max_depth = 5, n_estimators = 1000).fit(X_train_ensemble, Y_train)\n",
    "\n",
    "sub['fare_amount'] = ensemble_md.predict(X_test_ensemble)\n",
    "\n",
    "sub.to_csv('Submissions/ensemble_rd4.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589748d-1f8e-4fe0-b032-b79350483cdc",
   "metadata": {},
   "source": [
    "### Fifth Round of Models: Optimized hps, new features, with top __ features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ef0e4-efe9-4660-abda-6123b82873ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "X_train_XGB = train.drop(columns = ['fare_amount'])\n",
    "Y_train_XGB = train['fare_amount']\n",
    "\n",
    "X_test = test\n",
    "\n",
    "## XGBoost Model:\n",
    "XGB_md = XGBRegressor(tree_method = 'hist', n_estimators = 300, learning_rate = 0.02, max_depth = 5, gamma = 0.2, \n",
    "                      min_child_weight = 6, subsample = 0.99, colsample_bytree = 0.74, verbosity = 0).fit(X_train_XGB, Y_train_XGB)\n",
    "\n",
    "XGB_preds = XGB_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = XGB_preds\n",
    "\n",
    "sub.to_csv('Submissions/xgb_rd3a.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee33dafd-abb1-4c75-b443-e4727d8801a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "X_train_XGB = train.drop(columns = ['fare_amount', 'Tuesday', 'Wednesday', 'dropoff_LGA', 'pickup_JFK', 'pickup_EWR', 'dropoff_EWR', \n",
    "                                   'pickup_bronx', 'pickup_brooklyn', 'pickup_staten_island', 'dropoff_bronx', 'dropoff_brooklyn', \n",
    "                                   'dropoff_queens', 'dropoff_staten_island'])\n",
    "Y_train_XGB = train['fare_amount']\n",
    "\n",
    "X_test = test.drop(columns = ['Tuesday', 'Wednesday', 'dropoff_LGA', 'pickup_JFK', 'pickup_EWR', 'dropoff_EWR', 'pickup_bronx', \n",
    "                              'pickup_brooklyn', 'pickup_staten_island', 'dropoff_bronx', 'dropoff_brooklyn', 'dropoff_queens', \n",
    "                              'dropoff_staten_island'])\n",
    "\n",
    "## XGBoost Model:\n",
    "XGB_md = XGBRegressor(tree_method = 'hist', n_estimators = 300, learning_rate = 0.02, max_depth = 5, gamma = 0.2, \n",
    "                      min_child_weight = 6, subsample = 0.99, colsample_bytree = 0.74, verbosity = 0).fit(X_train_XGB, Y_train_XGB)\n",
    "\n",
    "XGB_preds = XGB_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = XGB_preds\n",
    "\n",
    "sub.to_csv('Submissions/xgb_rd3b.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8bb192-1b22-4c14-9cd4-8226dd42c68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "X_train_lgbm = train.drop(columns = ['fare_amount'])\n",
    "Y_train_lgbm = train['fare_amount']\n",
    "\n",
    "X_test = test\n",
    "\n",
    "## LightGBM Model:\n",
    "lgbm_md = LGBMRegressor(boosting_type = 'dart', n_estimators = 1200, learning_rate = 0.06, num_leaves = 9, max_depth = 3,\n",
    "                      subsample = 0.82, colsample_bytree = 0.9, random_state = 660, reg_alpha = 0.042, reg_lambda = 0.066, \n",
    "                        objective = 'rmse', verbosity = -1).fit(X_train_lgbm, Y_train_lgbm)\n",
    "\n",
    "lgbm_preds = lgbm_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = lgbm_preds\n",
    "\n",
    "sub.to_csv('Submissions/lgbm_rd3a.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6907d5-fa80-4f98-9b40-a7d649c9743b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "X_train_lgbm = train.drop(columns = ['fare_amount', 'Tuesday', 'Wednesday', 'dropoff_LGA', 'pickup_JFK', 'pickup_EWR', 'dropoff_EWR', \n",
    "                                    'pickup_bronx', 'pickup_brooklyn', 'pickup_staten_island', 'dropoff_bronx', 'dropoff_brooklyn', \n",
    "                                    'dropoff_queens', 'dropoff_staten_island'])\n",
    "Y_train_lgbm = train['fare_amount']\n",
    "\n",
    "X_test = test.drop(columns = ['Tuesday', 'Wednesday', 'dropoff_LGA', 'pickup_JFK', 'pickup_EWR', 'dropoff_EWR', 'pickup_bronx', \n",
    "                              'pickup_brooklyn', 'pickup_staten_island', 'dropoff_bronx', 'dropoff_brooklyn', 'dropoff_queens', \n",
    "                              'dropoff_staten_island'])\n",
    "\n",
    "## LightGBM Model:\n",
    "lgbm_md = LGBMRegressor(boosting_type = 'dart', n_estimators = 1200, learning_rate = 0.06, num_leaves = 9, max_depth = 3,\n",
    "                      subsample = 0.82, colsample_bytree = 0.9, random_state = 660, reg_alpha = 0.042, reg_lambda = 0.066, \n",
    "                        objective = 'rmse', verbosity = -1).fit(X_train_lgbm, Y_train_lgbm)\n",
    "\n",
    "lgbm_preds = lgbm_md.predict(X_test)\n",
    "\n",
    "sub['fare_amount'] = lgbm_preds\n",
    "\n",
    "sub.to_csv('Submissions/lgbm_rd3b.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
